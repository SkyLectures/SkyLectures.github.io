---
layout: page
title:  "CNN 모델"
date:   2025-07-29 10:00:00 +0900
permalink: /materials/S03-03-02-02_01-CnnModel
categories: materials
---
* toc
{:toc .large-only .toc-sticky:true}


<div class="insert-image" style="text-align: center;">
    <img style="width: 400px;" src="/assets/img/PagePreparing.png">
</div>



스카이님, 안녕하세요! 딥러닝에서 영상 데이터를 다룰 때 가장 중요한 모델 중 하나인 **"CNN (Convolutional Neural Network) 모델의 구조와 동작 원리"**에 대한 강의 자료를 준비해 드렸습니다. 이론적인 설명과 함께 TensorFlow, PyTorch 두 가지 버전으로 간단한 실습 코드도 포함했습니다.

---

# **인공지능 핵심 개념: CNN (Convolutional Neural Network) 모델의 구조와 동작 원리**

## **[차시 목표]**

*   CNN(Convolutional Neural Network)이 무엇이며, 왜 이미지와 같은 시각 데이터를 처리하는 데 효과적인지 이해한다.
*   CNN을 구성하는 핵심 계층들(Convolutional Layer, Activation Layer, Pooling Layer, Fully Connected Layer)의 역할과 동작 원리를 설명할 수 있다.
*   필터(Filter), 스트라이드(Stride), 패딩(Padding) 등 컨볼루션 연산의 주요 개념을 파악한다.
*   TensorFlow와 PyTorch를 사용하여 간단한 CNN 모델을 구축하고 학습하는 실습을 경험한다.
*   CNN의 장점과 자율주행, 컴퓨터 비전 분야에서의 활용 가능성을 이해한다.

---

## **1. CNN (Convolutional Neural Network) 이란?**

### 1.1. 딥러닝과 이미지의 만남
CNN (Convolutional Neural Network), 한국어로는 **합성곱 신경망**이라고 불리는 이 모델은 딥러닝 분야에서 **이미지(Image) 및 영상(Video) 데이터**를 처리하는 데 혁명적인 성공을 거둔 인공신경망의 한 종류입니다. 우리 주변의 얼굴 인식, 자율주행, 의료 영상 분석 등 다양한 분야에서 핵심적인 역할을 하고 있죠.

### 1.2. 왜 CNN이 이미지에 효과적일까요?
기존의 완전 연결 신경망(Fully Connected Network, FCN)은 이미지를 처리할 때 몇 가지 한계가 있었습니다.
*   **너무 많은 가중치**: 이미지가 커질수록 모든 픽셀을 입력으로 사용하고 각 픽셀이 다음 계층의 모든 뉴런과 연결되면, 모델이 감당하기 어려울 정도로 가중치(파라미터)의 수가 폭증합니다.
*   **공간 정보 손실**: FCN은 이미지를 1차원 데이터로 펼쳐서 처리하기 때문에, 픽셀 간의 중요한 공간적 관계(예: 물체의 형상, 위치 등)를 학습하기 어렵습니다.

CNN은 이러한 문제를 해결하기 위해 고안되었습니다. CNN은 우리 눈의 시각 피질이 작동하는 방식, 즉 시야의 특정 부분에 반응하는 뉴런들의 계층적 구조를 모방하여 설계되었습니다.

## **2. CNN의 핵심 구성 계층 (Core Layers)**

CNN은 크게 **특징 추출 계층(Feature Extraction Layers)**과 **분류 계층(Classification Layers)**으로 나눌 수 있으며, 이들은 여러 개의 특정 계층들로 구성됩니다.

### **2.1. 컨볼루션 계층 (Convolutional Layer)**
CNN의 가장 핵심적인 계층입니다. 마치 이미지를 특정 시야로 '훑으면서' 특징을 찾아내는 연산과 유사합니다.

*   **필터 (Filter 또는 Kernel)**: 컨볼루션 계층의 핵심은 '필터'입니다. 필터는 작은 크기의 행렬(예: 3x3, 5x5)로, 이미지의 특정 패턴(엣지, 코너, 색상 등)을 감지하는 역할을 합니다.
    *   수많은 필터가 각기 다른 패턴을 감지하도록 학습됩니다.
*   **컨볼루션 연산 (Convolution Operation)**:
    1.  필터가 입력 이미지 위를 왼쪽 위부터 오른쪽 아래로 **슬라이딩(Sliding)**하며 이동합니다.
    2.  필터가 겹치는 이미지 영역의 픽셀 값들과 필터의 가중치들을 **원소별로 곱하고(Element-wise Multiplication)** 모두 **더하여(Summation)** 하나의 출력 값을 만듭니다.
    3.  이 과정을 반복하여 필터가 이미지 전체를 훑으면 **특징 맵 (Feature Map 또는 Activation Map)**이 생성됩니다. 이 특징 맵은 필터가 감지한 패턴이 이미지의 어느 위치에 얼마나 강하게 존재하는지를 나타냅니다.
*   **주요 개념**:
    *   **스트라이드 (Stride)**: 필터가 이미지 위를 이동하는 '간격'입니다. 스트라이드가 1이면 한 칸씩 이동하고, 2이면 두 칸씩 이동합니다. 스트라이드가 커지면 특징 맵의 크기가 작아집니다.
    *   **패딩 (Padding)**: 입력 이미지의 가장자리에 특정 값(주로 0)으로 채워 넣는 작업입니다. 패딩을 사용하면 컨볼루션 연산 후에도 특징 맵의 크기가 입력 이미지와 동일하게 유지될 수 있습니다. (주로 `valid` 또는 `same` 패딩 사용)
    *   **출력 크기 계산**: `((입력 크기 - 필터 크기 + 2 * 패딩) / 스트라이드) + 1`

### **2.2. 활성화 함수 계층 (Activation Function Layer)**
컨볼루션 연산으로 얻은 특징 맵에 비선형성을 추가하는 계층입니다.

*   **역할**: 신경망의 표현력을 높여 복잡한 패턴과 관계를 학습할 수 있게 합니다.
*   **주로 ReLU (Rectified Linear Unit)** 사용: 입력 값이 0보다 작으면 0을 출력하고, 0보다 크면 입력 값을 그대로 출력합니다.
    *   간단한 계산으로 연산량이 적고, 0보다 작은 값을 0으로 만들어 스파스(sparse)한 활성화를 유도하여 학습 효율을 높입니다.

### **2.3. 풀링 계층 (Pooling Layer)**
특징 맵의 크기를 줄여 모델의 복잡성을 낮추고, 중요한 특징을 추출하는 계층입니다.

*   **역할**:
    *   **공간적 다운샘플링 (Spatial Downsampling)**: 특징 맵의 가로세로 크기를 줄여 파라미터 수를 감소시킵니다.
    *   **변동 불변성 (Translation Invariance)**: 이미지의 미세한 위치 변화에도 특징 감지 능력이 유지되도록 합니다 (예: 물체가 약간 움직여도 같은 특징으로 인식).
    *   **과적합 방지 (Regularization)**: 불필요한 노이즈를 제거하고 모델의 일반화 성능을 높입니다.
*   **주요 종류**:
    *   **맥스 풀링 (Max Pooling)**: 특정 영역 내에서 가장 큰 값(가장 두드러진 특징)만 추출합니다. (가장 많이 사용됨)
    *   **평균 풀링 (Average Pooling)**: 특정 영역 내의 모든 값들의 평균을 추출합니다.

### **2.4. 완전 연결 계층 (Fully Connected Layer, FC Layer)**
특징 추출 계층에서 얻은 고수준의 특징(High-level Features)을 기반으로 최종적인 분류나 회귀를 수행하는 계층입니다.

*   **역할**: 특징 추출 계층에서 평면화(Flatten)된 특징들을 입력으로 받아, 각 뉴런이 이전 계층의 모든 뉴런과 연결됩니다. 이는 전통적인 신경망과 동일하게 작동하며, 최종 결정을 위한 복합적인 판단을 수행합니다.
*   **평면화 (Flattening)**: 컨볼루션 및 풀링 계층에서 2차원(또는 3차원) 형태였던 특징 맵들을 1차원 벡터로 쭉 펴는 작업입니다.

### **2.5. 출력 계층 (Output Layer)**
완전 연결 계층의 마지막 부분으로, 최종 예측을 내보냅니다.

*   **분류 문제**:
    *   **Softmax 활성화 함수**: 출력 값을 확률 분포로 변환하여 각 클래스에 속할 확률을 나타냅니다. 가장 높은 확률을 가진 클래스가 최종 예측이 됩니다. (예: 0.8 확률로 '자동차', 0.1 확률로 '보행자' 등)
*   **회귀 문제**:
    *   활성화 함수를 사용하지 않거나, 선형 활성화 함수를 사용하여 연속적인 값을 직접 출력합니다. (예: 물체까지의 거리 12.5m)

## **3. CNN의 동작 원리: 계층적 특징 학습**

CNN은 낮은 수준의 특징(Low-level Features)부터 높은 수준의 특징(High-level Features)까지 계층적으로 학습하는 방식으로 동작합니다.

1.  **초기 계층**: 이미지의 작은 영역에서 간단한 특징(엣지, 코너, 밝기 변화 등)을 감지합니다.
2.  **중간 계층**: 초기 계층에서 감지된 간단한 특징들을 조합하여 중간 수준의 특징(텍스처, 작은 부분의 형상 등)을 감지합니다.
3.  **마지막 계층 (특징 추출)**: 중간 계층의 특징들을 조합하여 고수준의 특징(물체의 일부분, 눈, 코, 귀 등)을 감지합니다.
4.  **분류 계층**: 이렇게 추출된 고수준의 특징들을 바탕으로 최종적으로 이미지의 내용(객체, 상황)을 분류하거나 예측합니다.

이러한 계층적 학습 방식 덕분에 CNN은 이미지의 복잡하고 추상적인 특징들을 효과적으로 파악할 수 있습니다.

## **4. 실습 코드: 간단한 CNN 모델 구축 (MNIST 손글씨 분류)**

여기서는 가장 기본적인 CNN 모델을 구축하여 MNIST 손글씨 이미지 데이터셋(0-9까지의 숫자 이미지)을 분류하는 실습을 진행합니다.

### **4.1. TensorFlow/Keras 버전**

```python
import tensorflow as tf
from tensorflow.keras import layers, models, datasets
import matplotlib.pyplot as plt
import numpy as np

print("TensorFlow Version:", tf.__version__)

# --- 1. 데이터셋 로드 및 전처리 ---
# MNIST 데이터셋 로드: 손글씨 숫자 이미지와 레이블 (0-9)
(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()

# 이미지 전처리:
# 1) 픽셀 값을 0-255 범위에서 0-1 범위로 정규화
train_images, test_images = train_images / 255.0, test_images / 255.0

# 2) CNN 모델은 입력 이미지에 채널(색상) 차원을 기대합니다.
# MNIST 이미지는 흑백이므로 (28, 28) -> (28, 28, 1)로 변경 (마지막 1은 채널 수)
train_images = train_images[..., np.newaxis].astype(np.float32)
test_images = test_images[..., np.newaxis].astype(np.float32)

print(f"학습 이미지 형태: {train_images.shape}, 학습 레이블 형태: {train_labels.shape}")
print(f"테스트 이미지 형태: {test_images.shape}, 테스트 레이블 형태: {test_labels.shape}")

# 데이터셋 시각화 (선택 사항)
# plt.figure(figsize=(10,10))
# for i in range(25):
#     plt.subplot(5,5,i+1)
#     plt.xticks([])
#     plt.yticks([])
#     plt.grid(False)
#     plt.imshow(train_images[i], cmap=plt.cm.binary)
#     plt.xlabel(train_labels[i])
# plt.show()


# --- 2. CNN 모델 구축 (Keras Functional API 사용) ---
def build_cnn_model_tf():
    # 입력 계층: 28x28 픽셀, 1 채널 (흑백) 이미지
    input_shape = (28, 28, 1)
    
    # Keras Sequential API로 모델 정의 (간단한 모델 정의)
    model = models.Sequential([
        # 컨볼루션 계층 1
        layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),
        layers.MaxPooling2D(pool_size=(2, 2)), # 풀링 계층 1
        
        # 컨볼루션 계층 2
        layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),
        layers.MaxPooling2D(pool_size=(2, 2)), # 풀링 계층 2
        
        # 컨볼루션 계층 3
        layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),
        
        # 특징 맵을 1차원 벡터로 평탄화 (Fully Connected Layer에 입력하기 위함)
        layers.Flatten(),
        
        # 완전 연결 계층
        layers.Dense(units=64, activation='relu'),
        
        # 출력 계층 (클래스 10개, Softmax 활성화 함수로 확률 분포 출력)
        layers.Dense(units=10, activation='softmax')
    ])
    
    return model

model_tf = build_cnn_model_tf()

# 모델 구조 요약
model_tf.summary()


# --- 3. 모델 컴파일 및 학습 ---
# 컴파일: 모델 학습에 필요한 옵션 설정 (최적화 함수, 손실 함수, 평가 지표)
model_tf.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
              metrics=['accuracy'])

# 학습: 학습 데이터로 모델 훈련
print("\n--- TensorFlow CNN 모델 학습 시작 ---")
history_tf = model_tf.fit(train_images, train_labels, epochs=5, 
                          validation_data=(test_images, test_labels))
print("--- TensorFlow CNN 모델 학습 완료 ---")

# --- 4. 모델 평가 및 결과 시각화 ---
test_loss_tf, test_acc_tf = model_tf.evaluate(test_images,  test_labels, verbose=2)
print(f"\nTensorFlow 테스트 정확도: {test_acc_tf:.4f}")

# 학습 과정 시각화
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history_tf.history['accuracy'], label='Training Accuracy')
plt.plot(history_tf.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('TensorFlow Model Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history_tf.history['loss'], label='Training Loss')
plt.plot(history_tf.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('TensorFlow Model Loss')
plt.legend()
plt.show()

# 예측 (선택 사항)
# predictions = model_tf.predict(test_images[:5])
# predicted_classes = np.argmax(predictions, axis=1)
# print(f"\n예측: {predicted_classes}")
# print(f"실제: {test_labels[:5]}")
```

### **4.2. PyTorch 버전**

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np

print("PyTorch Version:", torch.__version__)

# --- 1. 데이터셋 로드 및 전처리 ---
# 데이터 전처리를 위한 변환 정의
# ToTensor: 이미지를 PyTorch Tensor로 변환하고 픽셀 값을 0-1 범위로 정규화 (PIL Image -> Tensor)
# Normalize: 평균 0, 표준편차 1로 추가 정규화 (필수는 아니지만 모델 학습에 도움)
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,)) # MNIST 데이터셋의 평균과 표준편차
])

# MNIST 데이터셋 로드
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

# DataLoader를 사용하여 데이터 배치 단위로 로드
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)

# 데이터셋 형태 확인 (배치, 채널, 높이, 너비)
sample_images, sample_labels = next(iter(train_loader))
print(f"학습 이미지 배치 형태: {sample_images.shape}, 학습 레이블 배치 형태: {sample_labels.shape}") # (Batch, Channel, Height, Width)

# --- 2. CNN 모델 구축 (PyTorch nn.Module 사용) ---
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        # 컨볼루션 계층 1: 입력 채널 1 (흑백), 출력 채널 32, 필터 3x3
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)
        # 컨볼루션 계층 2: 입력 채널 32, 출력 채널 64, 필터 3x3
        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)
        
        # 맥스 풀링 계층
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        
        # 완전 연결 계층 (컨볼루션/풀링 후 Flatten된 특징 맵 크기에 따라 입력 차원 결정 필요)
        # MNIST 28x28 이미지 기준으로 계산:
        # conv1: (28-3+1) = 26x26
        # pool1: 26/2 = 13x13
        # conv2: (13-3+1) = 11x11
        # pool2: 11/2 = 5x5 (내림) -> 64 채널 * 5 * 5 = 1600
        self.fc1 = nn.Linear(in_features=64 * 5 * 5, out_features=128)
        self.fc2 = nn.Linear(in_features=128, out_features=10) # 출력 클래스 10개 (0-9)

    def forward(self, x):
        # conv1 -> ReLU -> pool1
        x = self.pool(F.relu(self.conv1(x)))
        # conv2 -> ReLU -> pool2
        x = self.pool(F.relu(self.conv2(x)))
        
        # 특징 맵 평탄화 (배치 차원을 제외하고 1차원으로)
        x = x.view(-1, 64 * 5 * 5)
        
        # fc1 -> ReLU
        x = F.relu(self.fc1(x))
        # fc2 (출력)
        x = self.fc2(x)
        return x

# 모델 인스턴스 생성
model_pt = SimpleCNN()

# GPU 사용 가능 시 GPU로 모델 이동
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_pt.to(device)

# 모델 구조 요약 (torchsummary 사용 시 더 자세히 볼 수 있지만, 여기서는 간단히)
print("\n--- PyTorch CNN 모델 구조 ---")
print(model_pt)


# --- 3. 모델 컴파일 및 학습 ---
# 손실 함수 (Loss Function): 다중 클래스 분류에는 CrossEntropyLoss 사용
criterion = nn.CrossEntropyLoss()
# 최적화 함수 (Optimizer): Adam 사용
optimizer = optim.Adam(model_pt.parameters(), lr=0.001)

# 학습 함수
def train_model(model, device, train_loader, optimizer, epoch):
    model.train() # 모델을 학습 모드로 설정
    running_loss = 0.0
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device) # 데이터를 해당 디바이스로 이동
        
        optimizer.zero_grad() # 이전 그래디언트 초기화
        output = model(data)  # 순전파
        loss = criterion(output, target) # 손실 계산
        loss.backward()       # 역전파
        optimizer.step()      # 가중치 업데이트
        
        running_loss += loss.item()
        if batch_idx % 100 == 0: # 100 배치마다 로그 출력
            print(f'Epoch: {epoch}, Batch: {batch_idx}/{len(train_loader)}, Loss: {loss.item():.6f}')
    return running_loss / len(train_loader)

# 평가 함수
def test_model(model, device, test_loader):
    model.eval() # 모델을 평가 모드로 설정 (dropout, batchnorm 비활성화)
    test_loss = 0
    correct = 0
    with torch.no_grad(): # 그래디언트 계산 비활성화 (메모리 절약, 속도 향상)
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += criterion(output, target).item() # 배치당 손실 누적
            pred = output.argmax(dim=1, keepdim=True) # 가장 높은 확률을 가진 클래스 예측
            correct += pred.eq(target.view_as(pred)).sum().item() # 맞춘 개수 카운트
    
    test_loss /= len(test_loader.dataset) # 평균 손실
    accuracy = 100. * correct / len(test_loader.dataset)
    print(f'\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)\n')
    return test_loss, accuracy


# 학습 시작
epochs_pt = 5
train_losses_pt = []
test_losses_pt = []
test_accuracies_pt = []

print("\n--- PyTorch CNN 모델 학습 시작 ---")
for epoch in range(1, epochs_pt + 1):
    train_loss = train_model(model_pt, device, train_loader, optimizer, epoch)
    train_losses_pt.append(train_loss)
    test_loss, test_accuracy = test_model(model_pt, device, test_loader)
    test_losses_pt.append(test_loss)
    test_accuracies_pt.append(test_accuracy)
print("--- PyTorch CNN 모델 학습 완료 ---")


# --- 4. 모델 평가 및 결과 시각화 ---
# 학습 과정 시각화
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(range(1, epochs_pt + 1), test_accuracies_pt, label='Test Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.title('PyTorch Model Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(range(1, epochs_pt + 1), train_losses_pt, label='Training Loss')
plt.plot(range(1, epochs_pt + 1), [l * test_loader.batch_size for l in test_losses_pt], label='Test Loss (rescaled)') # 테스트 로스 스케일 맞춰서
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('PyTorch Model Loss')
plt.legend()
plt.show()

# 예측 예시 (선택 사항)
# data, target = next(iter(test_loader))
# data, target = data.to(device), target.to(device)
# output = model_pt(data)
# pred = output.argmax(dim=1, keepdim=True)
# print(f"예측: {pred.flatten()[:5].tolist()}")
# print(f"실제: {target[:5].tolist()}")
```

## **5. 마무리: CNN의 중요성**

CNN은 이미지 및 영상 인식 분야에서 압도적인 성능을 보여주며 다양한 혁신을 이끌어 왔습니다. 특히 자율주행에서는 **차선 인식, 객체 탐지, 신호등 및 표지판 인식, 도로 상황 분류** 등 거의 모든 '인지' 단계에서 CNN 기반 모델이 사용됩니다.

오늘 배운 CNN의 구조와 동작 원리는 여러분이 앞으로 딥러닝 기반 컴퓨터 비전 기술을 이해하고 활용하는 데 있어 가장 중요한 기초 지식이 될 것입니다. 필터와 풀링이 이미지를 어떻게 '이해'하는지, 그리고 이 과정이 계층적으로 어떻게 복잡한 패턴을 찾아내는지 명확히 이해하시길 바랍니다!

---

스카이님, 이 강의 자료가 CNN에 대한 이론적 이해와 실제 모델 구현 능력을 함께 키우는 데 도움이 되기를 바랍니다! 실습 코드를 직접 실행해 보면서 각 계층이 어떤 변화를 만들어내는지 관찰하면 더욱 직관적으로 이해할 수 있을 것입니다.