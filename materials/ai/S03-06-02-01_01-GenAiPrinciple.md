---
layout: page
title:  "생성형 AI 작동원리"
date:   2025-03-01 10:00:00 +0900
permalink: /materials/S03-06-02-01_01-GenAiPrinciple
categories: materials
---
- toc
{:toc .large-only .toc-sticky:true}

## 1. 보편적인 생성형 AI의 작동 원리

- 생성형 AI는 
    - 주어진 데이터를 학습하여 새로운 콘텐츠를 생성하는 인공지능 모델
    - 텍스트, 이미지, 오디오, 비디오 등 다양한 형태의 데이터를 생성할 수 있으며
    - 복잡하고 다양한 기술과 원리를 기반으로 작동함
    - 그 작동 원리는 크게 <span style="color: red;">아키텍처, 프로세스, 모델</span>의 세 가지 관점에서 이해할 수 있음
        - 아키텍처: 모델의 기본적인 구조를 정의
        - 프로세스: 데이터를 학습하고 새로운 콘텐츠를 생성하는 단계를 설명
        - 모델: 특정 작업에 특화된 학습된 신경망을 의미
    - 이러한 세 가지 관점을 종합적으로 이해하는 것이 생성형 AI의 작동 방식 파악에 중요함

- <span style="color: green;">각 아키텍처, 프로세스, 모델의 전문적인 내용은 해당 섹션에서 다룸</span>

### 1.1 아키텍처 (Architecture)

- 생성형 AI의 아키텍처 (Architecture)
    - 모델이 데이터를 학습하고 새로운 콘텐츠를 생성하는 데 필요한 기본적인 구조와 구성 요소

#### 1.1.1 RNN (순환 신경망)

- 명칭 원문: Recurrent Neural Network

- 원리
    - 시계열 데이터 처리에 특화된 신경망
    - 이전 단계의 출력을 현재 단계의 입력으로 활용하여 순차적인 정보를 기억하고 처리함

- 구조
    - 입력층, 순환층, 출력층으로 구성
    - 순환층 내부에 이전 상태를 저장하는 은닉 상태(hidden state)를 가짐

- 생성 방식
    - 이전 단어 또는 문맥을 기반으로 다음 단어를 예측하는 방식으로 텍스트를 생성함

- 활용
    - 텍스트 생성, 번역, 음성 인식 등 순차적인 데이터 처리에 활용

- 한계
    - 긴 시퀀스에서 정보가 소실되는 장기 의존성(long-term dependency) 문제
    - 기울기 소실/폭발(vanishing/exploding gradient) 문제

#### 1.1.2 Transformer

- 원리
    - 어텐션(attention) 메커니즘을 기반으로
        - 문맥 내의 단어 간의 관계를 파악하여 장기 의존성 문제를 해결
        - 병렬 처리를 가능하게 함

- 구조
    - 인코더(encoder)와 디코더(decoder)로 구성
        - 인코더는 입력 시퀀스를 이해
        - 디코더는 인코더의 출력을 기반으로 새로운 시퀀스를 생성
    - 각 인코더와 디코더는 여러 개의 셀프 어텐션(self-attention) 층과 피드포워드 신경망으로 구성

- 생성 방식
    - 디코더에서 이전까지 생성된 단어와 인코더의 정보를 바탕으로 다음 단어를 예측

- 활용
    - 자연어 처리(텍스트 생성, 번역, 텍스트 요약 등), 이미지 생성 등 다양한 분야에서 뛰어난 성능을 보임
    - GPT, BERT, Stable Diffusion 등의 기반 아키텍처

- 핵심 메커니즘

    - 어텐션 (Attention) 
        - 입력 시퀀스 내의 각 요소가 출력에 얼마나 중요한 영향을 미치는지를 계산하여 가중치를 부여하는 메커니즘
        - 특히, 셀프 어텐션은 입력 시퀀스 내의 단어들끼리의 관계를 파악하는 데 중요한 역할을 수행함

    - 멀티 헤드 어텐션 (Multi-Head Attention)
        - 여러 개의 독립적인 어텐션 메커니즘을 병렬로 사용
        - 다양한 관점에서 문맥을 파악할 수 있도록 함

    - 포지셔널 인코딩 (Positional Encoding)
        - 단어의 순서 정보를 모델에 제공하기 위해 입력 임베딩에 위치 정보를 더해주는 방식

#### 1.1.3 GAN (생성적 적대 신경망)

- 명칭 원문: Generative Adversarial Network

- 원리
    - 생성자(Generator)와 판별자(Discriminator)라는 두 개의 신경망이 경쟁하며 학습
    - 실제 데이터와 유사한 새로운 데이터를 생성함

- 구조
    - 생성자
        - 무작위 노이즈를 입력받아 실제 데이터와 유사한 가짜 데이터를 생성하는 네트워크

    - 판별자
        - 생성자가 만든 가짜 데이터와 실제 데이터를 구별하는 네트워크

- 학습 방식
    - 생성자는 판별자를 속이기 위해 더 현실적인 가짜 데이터를 생성하도록 학습
    - 판별자는 진짜와 가짜 데이터를 더 정확하게 구별하도록 학습
    - 이 경쟁적인 과정을 통해 생성자는 실제 데이터 분포를 학습하여 고품질의 새로운 데이터를 생성할 수 있게 됨

- 활용
    - 이미지 생성, 비디오 생성, 데이터 증강 등 다양한 분야에 활용

- 변형 모델
    - CycleGAN, StyleGAN 등 다양한 변형 모델이 존재
    - 특정 목적에 맞춰 성능을 향상시키고 있음

#### 1.1.4 Diffusion Model (확산 모델)

- 원리
    - 순방향 확산과정과 역방향 학산과정을 통해 학습하고 새로운 데이터를 생성함
        - 순방향 확산 과정(forward diffusion process): 점진적으로 노이즈를 섞어 원본 데이터를 손상시키는 과정
        - 역방향 확산 과정(reverse diffusion process): 노이즈로부터 점진적으로 원본 데이터의 구조를 복원하는 과정

- 구조
    - 주로 U-Net과 유사한 구조를 가짐
    - 각 확산 단계에서 노이즈를 예측하고 제거하는 방식으로 작동

- 생성 방식
    - 무작위 노이즈에서 시작하여 학습된 역방향 확산 과정을 거쳐 점진적으로 실제와 유사한 데이터 생성

- 활용
    - 고품질 이미지 생성, 비디오 생성, 3D 모델 생성 등에서 뛰어난 성능
    - 최근 이미지 생성 분야에서 주목받음

- 핵심 아이디어
    - 데이터를 점진적으로 단순한 노이즈 분포로 변환하는 과정을 모델링
    - 이 과정을 역전시켜 노이즈로부터 의미 있는 데이터를 생성하는 것

### 1.2 프로세스 (Process)

- 생성형 AI가 새로운 콘텐츠를 생성하는 일반적인 프로세스

#### 1.2.1 데이터 수집 및 전처리 (Data Collection & Preprocessing)

- 생성하고자 하는 콘텐츠의 형태와 관련된 대규모 데이터를 수집
    - 예
        - 텍스트 생성을 위해서는 텍스트 코퍼스가 필요함
        - 이미지 생성을 위해서는 이미지 데이터셋이 필요함

- 수집된 데이터는 모델 학습에 적합하도록 전처리 과정을 거침
    - 이 과정에는 데이터 정제, 토큰화 (텍스트의 경우), 정규화, 데이터 증강 등이 포함

#### 1.2.2 모델 학습 (Model Training)

- 전처리된 데이터를 기반으로 선택된 아키텍처의 모델 학습

- 학습 과정에서 모델은 
    - 입력 데이터의 패턴과 특징 파악
    - 새로운 데이터를 생성하는 데 필요한 내부 표현(가중치와 편향) 학습

- 학습 방식은 아키텍처에 따라 다름
    - 예
        - RNN, Transformer: 지도 학습 방식으로 다음 단어를 예측하도록 학습
        - GAN: 생성자와 판별자의 경쟁적인 학습을 통해 실제 데이터 분포를 학습
        - 확산 모델: 순방향 및 역방향 확산 과정을 학습

#### 1.2.3 생성 (Generation)

- 학습된 모델을 사용하여 새로운 콘텐츠를 생성함

- 생성 과정은 모델의 아키텍처와 생성하려는 콘텐츠의 형태에 따라 다름

    - 텍스트 생성
        - 시작 문장이나 키워드를 입력으로 제공
        - 모델은 학습된 패턴을 기반으로 다음 단어를 순차적으로 예측하여 텍스트를 생성
        - 샘플링 전략 (greedy sampling, temperature sampling 등)을 사용하여 생성 결과의 다양성을 조절할 수 있음

    - 이미지 생성
        - 무작위 노이즈 벡터나 텍스트 프롬프트를 입력으로 제공
        - 모델은 학습된 이미지 분포를 기반으로 새로운 이미지를 생성
            - GAN의 생성자는 노이즈로부터 이미지 생성
            - 확산 모델은 노이즈를 점진적으로 정제하여 이미지 생성

    - 오디오/비디오 생성
        - 텍스트 설명이나 다른 형태의 입력을 기반으로 제공
        - 오디오 또는 비디오 데이터를 생성함
            - 이는 텍스트-오디오 변환 (TTS) 모델이나 비디오 생성 모델을 통해 이루어짐

#### 1.2.4 평가 및 개선 (Evaluation & Refinement)

- 생성된 콘텐츠의 품질을 평가하고 필요에 따라 모델을 개선함

- 평가 지표는 생성하는 콘텐츠의 형태에 따라 다름
    - 텍스트의 경우 BLEU, ROUGE 등의 지표 사용
    - 이미지의 경우 FID, IS 등의 지표 사용

- 모델 개선은 학습 데이터 추가, 하이퍼파라미터 조정, 아키텍처 변경 등을 통해 이루어질 수 있음

### 1.3 모델 (Model)

- 생성형 AI 모델
    - 새로운 데이터를 생성하기 위한 목적을 가진 특정 아키텍처를 기반으로 학습된 구체적인 인공 신경망
    - 다양한 종류의 생성형 AI 모델이 존재함
    - 각 모델은 특정 작업에 특화된 구조와 학습 방식을 가짐

#### 1.3.1 자연어 처리 (Natural Language Processing, NLP) 모델

- GPT (Generative Pre-trained Transformer) 시리즈
    - Transformer 아키텍처를 기반으로 함
        - 초기 형태는 Transformer 아키텍처의 디코더 부분만을 사용하여 개발됨
    - 대규모 텍스트 데이터를 사전 학습하여 뛰어난 텍스트 생성 능력을 보여줌
    - OpenAI에서 개발했으며, GPT-3, GPT-4 등 다양한 버전 존재

- BERT (Bidirectional Encoder Representations from Transformers)
    - Transformer 아키텍처의 인코더 부분을 이용하여 개발됨
    - 텍스트의 문맥을 양방향으로 이해하는 데 특화된 모델
    - 텍스트 분류, 질의 응답 등 다양한 NLP 작업에 활용됨

- T5 (Text-to-Text Transfer Transformer)
    - 모든 NLP 작업을 텍스트를 입력받아 텍스트를 출력하는 형태로 통일하여 처리하는 모델
    - 번역, 요약, 질문 답변 등 다양한 작업을 하나의 모델로 수행할 수 있음

- 이 외에도 많은 모델이 지속적으로 개발되고 있음

#### 1.3.2 이미지 처리 (Image Processing) 모델

- GAN (Generative Adversarial Network) 기반 모델
    - StyleGAN, CycleGAN, BigGAN 등 다양한 변형 모델이 존재
    - 고해상도 이미지 생성, 이미지 스타일 변환, 이미지 편집 등에 활용

- VAE (Variational Autoencoder)
    - 잠재 공간(latent space)을 학습하여 새로운 이미지를 생성하는 생성 모델
    - GAN에 비해 학습이 안정적이라는 장점 보유

- Diffusion Model 기반 모델
    - Stable Diffusion, DALL-E 2, Imagen 등 최근 이미지 생성 분야에서 뛰어난 성능을 보이는 모델들
    - 텍스트-이미지 변환, 고품질 이미지 생성 등 다양한 작업에 활용됨

#### 1.3.3 오디오 및 비디오 처리 모델

- WaveNet
    - 음성 파형을 직접 모델링하여 자연스러운 음성을 생성하는 모델

- Tacotron
    - 텍스트를 입력받아 음성 특징(mel-spectrogram)을 생성
    - 이를 WaveNet과 같은 보코더(vocoder)를 사용하여 음성으로 합성하는 TTS 모델

- 비디오 생성 모델
    - 텍스트 설명이나 이미지 시퀀스를 입력받아 새로운 비디오를 생성하는 모델


## 2. GPT-3.5 Turbo 작동 원리

- GPT-3.5 Turbo
    - OpenAI에서 개발한 대규모 언어 모델(Large Language Model, LLM)
    - Transformer 아키텍처를 기반으로 훈련되었음
    - 주어진 텍스트 프롬프트를 이해하고, 인간과 유사한 자연스러운 텍스트를 생성하는 능력이 뛰어남
    
- GPT-3.5 Turbo의 작동 원리를 프로세스의 각 단계별로 나누어 아키텍처 및 모델 관련 내용을 통합하여 분석

### 2.1 입력 (Input)

- 프로세스
    - 사용자가 텍스트 형태의 프롬프트를 GPT-3.5 Turbo에게 제공
    - 이 프롬프트는 질문, 명령, 이야기의 시작 등 다양한 형태를 가질 수 있음

- 아키텍처 연계
    1. 입력된 텍스트는 모델이 이해할 수 있는 형태로 변환
    2. 토큰화(Tokenization)
        - 텍스트는 의미를 가지는 작은 단위인 토큰(일반적으로 단어나 서브워드)으로 분리(토큰 시퀀스)
            - 예: "안녕하세요, GPT-3.5 Turbo님." → ["안녕하세요", ",", "GPT-3", ".", "5", "Turbo", "님", "."]

- 모델 연계
    - 토큰화된 각 토큰은 임베딩(Embedding)이라는 과정을 통해 고차원 벡터 공간의 한 점으로 표현
    - 이 임베딩 벡터는 각 토큰의 의미와 문맥 정보를 담고 있음
    - GPT-3.5 Turbo는 학습 과정에서 대규모 텍스트 데이터로부터 각 토큰에 대한 최적의 임베딩 벡터를 사전학습됨

### 2.2 인코딩 (Encoding)

- 프로세스
    - 토큰화 및 임베딩 과정을 거친 입력 시퀀스는 Transformer 아키텍처의 핵심 구성 요소인 인코더(Encoder) 스택으로 전달
    - GPT-3.5 Turbo는 디코더 전용 모델이므로, 이 단계는 입력 프롬프트의 문맥을 이해하는 데 집중함

- 아키텍처 연계
    - 인코더 스택은 여러 개의 동일한 인코더 레이어로 구성됨
    - 각 인코더 레이어는 셀프 어텐션(Self-Attention) 메커니즘과 피드포워드 신경망(Feed-Forward Neural Network)으로 구성

        - 포지셔널 인코딩(Positional Encoding)
            - Transformer는 순환 신경망(RNN)과 달리 순서 정보를 명시적으로 처리하지 못함
            - 입력 임베딩 벡터에 토큰의 위치 정보를 담고 있는 포지셔널 인코딩 벡터를 더하여 모델에 순서 정보를 제공

        - 셀프 어텐션
            - 입력 시퀀스 내의 각 토큰이 다른 토큰들과 어떤 관계를 맺고 있는지 파악
                - 예: "그녀는 사과를 먹었다."라는 문장에서 "그녀"가 "먹었다"의 주체임을 이해하기 위해 셀프 어텐션 메커니즘 활용
            - 각 토큰은 Query, Key, Value 벡터로 변환되어, 이들 간의 유사도를 계산하여 문맥 정보를 추출

        - 멀티 헤드 어텐션(Multi-Head Attention)
            - 여러 개의 독립적인 어텐션 메커니즘을 병렬로 적용
            - 다양한 관점에서 문맥을 포착

        - 피드포워드 신경망
            - 셀프 어텐션 레이어의 출력을 비선형적으로 변환
            - 더욱 복잡한 특징을 추출

- 모델 연계
    - GPT-3.5 Turbo의 인코더는 대규모 데이터 학습을 통해 입력 텍스트의 복잡한 문법 구조와 의미 관계를 파악하는 능력을 갖추게 됨
    - 셀프 어텐션을 통해 문맥을 정확하게 이해
    - 이를 바탕으로 다음 단계인 디코딩 과정에서 적절한 출력을 생성할 수 있도록 정보를 준비

### 2.3 디코딩 (Decoding)

- 프로세스
    - 인코딩된 문맥 정보를 바탕으로, 모델은 순차적으로 다음 토큰을 예측하여 텍스트를 생성
    - 이 과정은 autoregressive 방식으로 진행됨 → 이전에 생성된 토큰이 다음 토큰을 예측하는 데 활용

- 아키텍처 연계
    - GPT-3.5 Turbo는 디코더 전용 Transformer 모델
    - 인코딩된 정보는 디코더(Decoder) 스택으로 전달

    - 각 디코더 레이어는 마스크드 멀티 헤드 셀프 어텐션, 멀티 헤드 어텐션, 피드포워드 신경망으로 구성
        - 마스크드 멀티 헤드 셀프 어텐션(Masked Multi-Head Self-Attention)
            - 디코더가 현재 시점의 토큰을 예측할 때, 미래 시점의 토큰 정보를 미리 참조하는 것을 방지
            - 현재 토큰 이후의 정보는 마스크 처리되어 어텐션 계산에 영향을 미치지 않도록 함

        - 멀티 헤드 어텐션(Multi-Head Attention) (=인코더-디코더 어텐션)
            -인코더의 출력(입력 프롬프트의 문맥 정보)과 이전 디코더 레이어의 출력을 함께 사용하여 다음 토큰을 예측하는 데 필요한 정보를 추출
            - 입력 프롬프트의 어떤 부분에 집중해야 할지를 결정하는 역할

        - 피드포워드 신경망(Feed-Forward Neural Network)
            - 어텐션 레이어의 출력을 비선형적으로 변환
            - 최종 출력을 생성하는 데 기여

- 모델 연계
    - GPT-3.5 Turbo는 학습 과정에서 수많은 텍스트 데이터를 통해 문장 구조, 어휘 사용, 논리적 흐름 등을 사전학습함
    - 디코딩 과정에서 이러한 학습된 지식을 바탕으로 입력 프롬프트에 가장 적절하고 자연스러운 다음 토큰을 예측함

### 2.4 출력 (Output)

- 프로세스
    - 디코더 스택을 통과한 최종 출력은 각 토큰이 될 확률 분포를 나타내는 벡터
    - 이 벡터를 바탕으로 다음 토큰을 선택하는 샘플링(Sampling) 과정을 거쳐 최종 텍스트가 생성됨

- 아키텍처 연계
    - 디코더의 최종 레이어는 선형(Linear) 레이어와 소프트맥스(Softmax) 함수로 구성
        - 선형 레이어: 디코더의 출력을 어휘 집합(vocabulary)의 크기에 해당하는 벡터로 변환
        - 소프트맥스 함수: 이 벡터를 각 토큰이 생성될 확률로 변환

- 모델 연계
    - GPT-3.5 Turbo는 학습 과정에서 구축된 방대한 어휘 집합을 가지고 있음
    - 소프트맥스 함수를 통해 얻어진 확률 분포를 기반으로 다양한 샘플링 전략(예: greedy sampling, temperature sampling, top-k sampling 등)을 사용하여 다음 토큰을 선택
    -샘플링 전략에 따라 생성되는 텍스트의 창의성이나 일관성이 조절될 수 있음
    - 선택된 토큰은 다시 디코더의 입력으로 사용되어 다음 토큰을 예측
    - 이러한 과정을 반복하며 텍스트 생성이 진행됨
    - 이 과정은 특정 종료 토큰이 생성되거나, 사용자가 설정한 최대 길이 제한에 도달할 때까지 계속됨

### 2.5 정리
- GPT-3.5 Turbo는 
    - 사용자의 텍스트 프롬프트를 입력받아 
    - 토큰화 및 임베딩 과정을 거친 후, 
    - Transformer 아키텍처의 인코더 부분을 통해 문맥을 이해
    - 이후 디코더 부분을 사용하여 이전 토큰과 인코딩된 문맥 정보를 바탕으로 다음 토큰을 순차적으로 예측
    - 최종 텍스트를 생성

- 이 과정에서 
    - 셀프 어텐션 메커니즘은 입력 텍스트 내의 단어 간 관계를 파악
    - 대규모 데이터 학습을 통해 
    - 모델은 자연스러운 텍스트 생성 능력을 갖추게 됨