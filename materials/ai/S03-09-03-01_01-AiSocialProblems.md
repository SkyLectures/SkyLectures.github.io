---
layout: page
title:  "인공지능의 사회적 문제"
date:   2025-03-01 10:00:00 +0900
permalink: /materials/S03-09-03-01_01_AiSocialProblems
categories: materials
---
* toc
{:toc .large-only .toc-sticky:true}

## 1. AI로 인해 유발될 수 있는 사회적, 윤리적 문제 및 사례

- AI 기술의 급속한 발전은 우리의 삶을 편리하게 만들지만, 동시에 다양한 사회적, 윤리적 문제들을 야기할 수 있음
- 아래의 사례 외에도 AI 기술의 발전은 예측 불가능한 다양한 사회적, 윤리적 문제들을 야기할 수 있음
- 따라서 AI 기술 개발과 함께 이러한 문제들에 대한 심층적인 논의와 해결책 마련이 필수적임

### 1.1 일자리 감소 및 경제적 불평등 심화

- **문제**
    - AI 기반 자동화 시스템 도입으로 인해 단순 반복 업무뿐만 아니라 전문직 영역에서도 일자리 감소가 발생
    - 이는 소득 불균형 심화 및 새로운 형태의 경제적 불평등을 초래할 수 있음

- **사례**
    - **공장 자동화**
        - 제조업 분야에서 로봇 및 AI 시스템 도입 → 생산 라인의 자동화가 진행되어 생산직 일자리 감소가 진행 중

    - **고객 상담 챗봇**
        - 금융, 통신 등 서비스 분야에서 AI 챗봇이 고객 상담 업무 수행 → 상담원 채용의 감소가 진행 중

    - **자율주행 트럭**
        - 자율주행 기술의 상용화 → 운송업 분야의 대규모 일자리 감소가 예상됨
        
    - **AI 변호사**
        - 간단한 법률 자문이나 문서 검토를 AI가 수행 → 일부 변호사 업무가 대체될 가능성이 제기됨

### 1.2 개인 정보 침해 및 감시 사회 심화

- **문제**
    - AI 시스템은 방대한 양의 데이터를 학습하고 활용함
    - 이 과정에서 개인 정보가 수집, 분석, 활용될 수 있음
    - 이는 사생활 침해, 감시 사회 심화, 데이터 오용 등의 문제를 야기할 수 있음

- **사례**
    - **얼굴 인식 기술**
        - 공공장소에 설치된 얼굴 인식 카메라를 통해
        - 개인의 동선 및 활동 정보가 수집되고 감시될 수 있음
        - 대표 사례: [중국의 '스카이넷' 시스템](https://dbr.donga.com/article/view/1206/article_no/9364/ac/magazine)

    - **맞춤형 광고 및 콘텐츠 추천**
        - AI 추천 알고리즘
            - 개인의 검색 기록, 구매 내역 등을 분석 → 맞춤형 광고나 콘텐츠를 제공 → 개인의 취향과 생각을 제한 → '필터 버블' 현상 심화 가능

    - **음성 인식 비서**
        - 스마트 스피커 등 음성 인식 기기
            - 사용자의 대화를 상시 청취하고 데이터를 수집 → 개인 정보 유출 위험을 증가시킬 수 있음

    - **소셜 크레딧 시스템**
        - 개인의 행동을 평가하여 사회적 신용 점수를 매기는 시스템
            - 개인의 자유를 제한하고 차별을 야기할 수 있음
            - 대표 사례: [중국의 사회신용 시스템](https://www.pado.kr/article/2024012610488843020)
                
                중국의 기존 법적, 재정적 신용 평가 시스템을 확장한 것<br>
                빅데이터를 활용해 국민에게 '행동점수'를 매겨서 고득점자에게 혜택을 수여, 저득점자에게 불이익을 주는 시스템
                {:.note title="중국의 사회신용 시스템"}


### 1.3 알고리즘 편향 및 차별 심화

- **문제**
    - AI 시스템은
        - 학습 데이터에 내재된 편향성을 그대로 학습하거나,
        - 알고리즘 설계 과정에서 의도치 않은 편향이 발생하여
        - 특정 집단에 불리하거나 차별적인 결과를 초래할 수 있음

- **사례**
    - **채용 AI**
        - 과거 채용 데이터에 특정 성별이나 인종에 대한 편견이 반영된 경우,
            - AI 채용 시스템이 특정 집단의 지원자를 부당하게 감점하거나 탈락시킬 수 있음
            - 대표 사례: 아마존의 AI 채용 도구가 여성 지원자에게 불리하게 작용한 사례

    - **대출 심사 AI**
        - 과거 대출 데이터에 특정 인종이나 지역에 대한 차별이 존재했던 경우,
            - AI 대출 심사 시스템이 해당 집단에 불리한 결과를 내릴 수 있음

    - **범죄 예측 AI**
        - 특정 지역이나 인종의 범죄 발생률이 높다는 과거 데이터를 학습한 AI가
            - 해당 집단의 범죄 위험도를 과도하게 예측하여
            - 불필요한 감시나 차별을 야기할 수 있음

    - **검색 엔진 및 소셜 미디어 알고리즘**
        - 특정 정치적 성향이나 사회적 이슈에 대한 편향된 정보를 우선적으로 노출시켜 사용자의 인식에 영향을 미칠 수 있음

### 1.4 책임 소재 불분명 및 법적 문제 발생

- **문제**
    - AI 시스템의 의사 결정 과정이 복잡하고 불투명하여
    - 예상치 못한 오류나 사고 발생 시 책임 소재를 규명하기 어려움
    - 이는 법적 분쟁 및 피해 구제의 어려움을 야기할 수 있음

* **사례**
    - **자율주행차 사고**
        - 자율주행차가 사고를 일으켰을 경우,
            - 제조사, 소프트웨어 개발사, 차량 소유자 중 누구에게 책임을 물어야 할지 법적 논쟁이 발생할 수 있음

    - **의료 AI 오진**
        - AI 기반 의료 진단 시스템이 오진을 내린 경우,
            - 의사, AI 개발사, 병원 중 누구에게 책임을 물어야 할지 불분명함

    - **AI 챗봇의 잘못된 정보 제공**
        - AI 챗봇이 잘못된 정보를 제공하여 사용자에게 피해를 입힌 경우,
            - 정보 제공의 책임을 누가 져야 할지 논란이 될 수 있음

### 1.5 인간 존엄성 및 자율성 침해

- **문제**
    - AI 기술이
        - 인간의 고유한 능력이나 가치를 대체하거나,
        - 인간의 의사 결정에 부당한 영향을 미쳐
        - 인간의 존엄성과 자율성을 침해할 수 있음

- **사례**
    - **소셜 로봇**
        - 감정 교류 기능을 가진 소셜 로봇이
            - 인간과의 깊은 유대감을 형성하면서
            - 인간 관계를 대체하거나 고립을 심화시킬 수 있다는 우려가 있음

    - **뇌-컴퓨터 인터페이스 (BCI)**
        - BCI 기술이 발전하면서
            - 인간의 생각이나 감정이 외부 장치에 직접 연결될 수 있으며
            - 이는 개인의 사생활 침해 및 자율성 침해 가능성을 내포함

    - **AI 기반 심리 조작**
        - AI 알고리즘이 개인의 심리적 취약성을 분석하여
            - 특정 행동을 유도하거나
            - 정치적 의견을 조작하는 데 사용될 수 있음

### 1.6 악용 가능성 및 보안 문제

- **문제**
    - AI 기술은 범죄, 테러, 사이버 공격 등 다양한 악의적인 목적으로 사용될 수 있음
    - AI 시스템 자체의 보안 취약성은 심각한 사회적 혼란을 야기할 수 있음

- **사례**
    - **자율 무기**
        - 인간의 개입 없이 스스로 판단하고 공격 대상을 결정하는 자율 무기의 개발 및 사용
            - 윤리적 논쟁을 불러일으키고
            - 오작동이나 오용으로 인한 심각한 결과를 초래할 수 있음

    - **딥페이크 기술**
        - AI 기반 딥페이크 기술을 이용하여 
            - 허위 영상이나 음성을 제작하고 유포하여
            - 개인의 명예를 훼손하거나 사회적 혼란을 야기할 수 있음

    - **AI 기반 사이버 공격**
        - AI를 활용하여 더욱 정교하고 지능적인 사이버 공격을 수행하여
            - 사회 기반 시설을 마비시키거나 
            - 중요한 정보를 탈취할 수 있음


## 2. 국내 AI 관련 사회적·윤리적 문제 사례 및 분석

- 국내에서도 AI 기술 발전과 함께 사회적·윤리적 문제들이 점차적으로 발생하고 있으며 이에 대한 사회적 논의와 문제 제기가 이루어지고 있음
- 국내의 사례들은 아직 초기 단계라고 할 수 있으므로 해외처럼 심각하거나 광범위한 사례는 상대적으로 적은 수준임
- 그러나 AI 기술이 우리 사회에 미치는 다양한 측면을 보여주고 있음<br><br>

- 이러한 사례들은 AI 기술 개발과 활용에 있어 윤리적 고려가 얼마나 중요한지, 그리고 잠재적인 위험을 방지하기 위한 사회적 논의와 제도적 장치 마련이 시급함을 시사함
- 앞으로 AI 기술이 더욱 발전하고 우리 삶 깊숙이 들어올수록, 이러한 문제들은 더욱 다양하고 심각한 형태로 나타날 수 있으며, 이에 대한 지속적인 관심과 적극적인 대응이 필요함

### 2.1 (2016) 알파고 vs 이세돌 이후 AI에 대한 막연한 기대와 우려

- **사건**
    - 2016년 3월, 구글 딥마인드의 AI 바둑 프로그램 알파고와 한국의 프로 바둑 기사 이세돌의 대국
        - 전 세계적으로 큰 관심을 불러 일으킴
        - 알파고의 승리는 AI의 잠재력을 극적으로 보여주는 동시에,
        - AI가 인간의 지적 능력을 넘어설 수 있다는 막연한 기대와 함께
        - 일자리 감소, 인간 소외 등 미래 사회에 대한 불안감을 증폭시키는 계기가 됨

- **문제점**
    - **비현실적인 기대와 과도한 공포**
        - AI 기술의 실제 수준과 적용 가능성에 대한 정확한 이해 없이
        - 지나치게 낙관적인 전망이나 비관적인 우려가 확산됨
        - 이는 사회적 논의의 방향을 왜곡하고, 현실적인 문제 해결 방안 모색에 어려움을 초래할 수 있음

    - **기술 결정론적 사고방식 강화**
        - AI 기술의 발전이 필연적으로 특정 사회적 결과를 가져올 것이라는 기술 결정론적 시각이 강화되어,
        - 인간의 노력과 사회적 합의를 통한 문제 해결의 중요성을 간과할 수 있음

- **의의**
    - **AI에 대한 사회적 관심 증대**
        - 이 사건은 일반 대중에게 AI 기술의 존재와 잠재력을 각인시키고
        - AI가 미래 사회에 미칠 영향에 대한 광범위한 관심을 불러일으킴

    - **AI 윤리 논의의 초기 촉발**
        - AI 기술의 발전 방향과 인간과의 관계에 대한 윤리적 고민의 필요성을 사회적으로 제기하는 계기가 됨

### 2.2 (2020) 이루다 AI 챗봇의 혐오 발언 및 개인 정보 침해 논란

- **사건**
    - 2020년 말 출시된 AI 챗봇 '이루다'(스캐터랩)
        - 특정 소수자에 대한 혐오 발언, 성적 대상화, 개인 정보 유출 등 다양한 논란에 휩싸임
        - 이루다는 20대 여성의 말투를 학습하여 자연스러운 대화를 표방했지만
        - 부적절한 학습 데이터와 필터링 미흡으로 인해 심각한 사회적·윤리적 문제를 야기함

- **문제점**
    - **AI 학습 데이터의 편향성 및 윤리적 문제**
        - AI 학습 데이터에 포함된 혐오 표현, 성차별적 내용 등이 AI 챗봇의 발언에 그대로 반영되어
        - 사회적 편견을 강화하고 혐오를 조장할 수 있음이 드러남

    - **개인 정보 침해 가능성**
        - 사용자들과의 대화 과정에서 수집된 민감한 개인 정보가 부적절하게 활용될 수 있다는 우려를 낳음
        - 특히, 연애 시뮬레이션 기능을 통해 수집된 개인 정보의 악용 가능성이 제기됨

    - **AI 개발 기업의 사회적 책임 부족**
        - AI 시스템의 윤리적 문제 발생 가능성에 대한 충분한 고려 없이 서비스를 출시하고,
        - 문제 발생 후에도 미흡한 대처로 비판

- **의의**
    - **AI 윤리 문제의 심각성 및 시급성 인식**
        - AI 기술 개발 및 활용에 있어 윤리적 문제에 대한 심각한 고민과 대비가 필수적임을 사회적으로 각인시키는 중요한 사례

    - **AI 규제 및 가이드라인 마련의 필요성 증대**
        - AI 기술의 잠재적 위험을 방지하고 사회적 신뢰를 확보하기 위한 법적·제도적 장치 마련의 필요성이 강력하게 제기됨

    - **AI 개발자와 사용자의 윤리적 책임 강조**
        - AI 시스템 개발자는 윤리적 기준을 준수하고 잠재적 위험을 최소화해야 하며,
        - 사용자 또한 AI 시스템을 책임감 있게 사용해야 함을 강조

### 2.3 (2023) AI 그림 생성 플랫폼의 저작권 및 윤리 문제 논란

- **사건**
    - AI 기반 그림 생성 플랫폼이 등장
        - 기존 화가들의 작품 스타일을 모방하거나, 학습 데이터에 포함된 저작권 침해 가능성이 있는 이미지 사용, 선정적이거나 혐오스러운 이미지 생성 등의 문제 제기
        - 이는 예술계의 저작권 침해 문제뿐만 아니라, AI가 생성한 창작물의 윤리적 책임 소재에 대한 논쟁을 불러일으킴 

- **문제점**
    - **AI 생성물의 저작권 문제**
        - AI가 학습한 데이터의 저작권 침해 여부
        - AI가 생성한 결과물의 저작권 귀속 문제 등
        - 법적 불확실성 존재

    - **기존 창작 생태계 위협**
        - AI 그림 생성 플랫폼의 확산이 기존 화가들의 창작 의욕 저하
        - 예술 시장의 질서를 혼란시킬 수 있다는 우려 제기

    - **윤리적 문제 이미지 생성 가능성**
        - AI가 사회적 통념에 어긋나거나 혐오감을 유발하는 이미지를 무분별하게 생성하고 유포할 수 있다는 위험성 존재

- **의의**
    - **AI와 지적재산권의 관계에 대한 논의 촉발**
        - AI 기술 발전과 함께 발생하는 새로운 형태의 지적재산권 문제에 대한 사회적, 법적 논의의 필요성 제기

    - **AI 생성물의 윤리적 책임 및 규제 필요성 강조**
        - AI가 생성한 콘텐츠의 사회적 영향에 대한 고민과 함께,
        - 이를 규제하고 관리할 수 있는 방안 마련의 중요성 부각

            본문에서 제기된 저작권 및 윤리 문제는 여전히 존재하고 있으나 창작자를 중심으로 AI 그림 생성 플랫폼의 활용이 확산되고 있음.<br>
            AI가 생성한 그대로의 결과물에는 저작권이 인정되지 않으나 AI의 생성결과에 창작자의 창작활동이 가미된 경우에는 저작권을 인정하는 사례가 늘고 있음.<br>
            또한 디지털 아트, AI Art 등의 창작 장르가 부상하며 [국제 전시회](https://zdnet.co.kr/view/?no=20250208173002)가 개최되는 등 창작자를 중심의 AI 활용이 확산되고 있음.
            {:.note title="AI 그림 생성 플랫폼의 최근 상황"}