---
layout: page
title:  "AI 모델 성능 평가 및 검증"
date:   2025-07-29 10:00:00 +0900
permalink: /materials/S03-10-02-03_01-AiModelEvaluationAndValidation
categories: materials
---
* toc
{:toc .large-only .toc-sticky:true}


## AI 모델 성능 평가 및 검증 기술 개요

- AI 모델의 성능 평가와 검증은 모델이 개발 의도대로 정확하고 안정적으로 작동하는지, 그리고 실제 환경에 적용했을 때에도 견고하게 예측할 수 있는지를 확인하는 일련의 과정
- 모델의 품질을 결정하고, 잠재적인 위험을 줄이며, 사용자에게 신뢰할 수 있는 서비스를 제공하기 위해 매우 중요

### 1. AI 모델 성능 평가의 필요성

- AI 모델은 학습 데이터에 오류가 있으면 예측에도 오류가 발생할 수 있음
- 다음과 같은 이유로 AI 모델의 성능 평가는 필수
    - **정확성(Accuracy) 확보**
        - 학습 데이터의 오류가 모델의 예측 오류로 이어지지 않도록 함
    - **신뢰성(Reliability) 증대**
        - AI 모델이 다양한 조건과 새로운 데이터에서도 일관된 성능을 유지하도록 함
    - **안전성(Safety) 보장**
        - 잘못된 예측이 잠재적인 위험을 초래하지 않도록 함
    - **일반화 능력(Generalization) 확인**
        - 모델이 훈련 데이터뿐만 아니라 이전에 본 적 없는 새로운 데이터에 대해서도 정확하게 예측하는 능력을 갖추도록 함

### 2. AI 모델 성능 평가 프로세스

- AI 모델의 정확도와 성능을 끌어올리기 위해서는 검증과 테스트를 반복해야 함
- 일반적인 프로세스
    1. **평가지표 선정**
        - 모델의 목적에 맞는 평가지표를 선정
            - 예: 정확도, 정밀도, 재현율 등
    2. **평가 규정 구축**
        - 테스트의 기준과 방법을 명확히 결정
    3. **테스트 데이터 준비**
        - 실제 상황과 유사하게 평가 데이터를 구성하는 것이 중요
        - 이 데이터를 통해 모델의 일반화 능력을 평가
    4. **평가 환경 구축**
        - 선정된 지표와 규정에 따라 모델을 테스트할 환경 마련
    5. **테스트 진행 및 반복**
        - 다양한 테스트 방법을 통해 모델의 성능을 평가
        - 필요에 따라 모델을 개선

### 3. 주요 AI 모델 성능 평가 지표

- 모델의 유형에 따라 적합한 평가 지표가 다름

#### 3.1 분류(Classification) 모델
- 특정 범주로 데이터를 분류하는 모델
    - 예: 스팸 메일 분류, 이미지 속 객체 인식<br><br>
- **정확도(Accuracy)**
    - 전체 예측 중 정확하게 맞춘 비율
- **정밀도(Precision)**
    - 모델이 긍정이라고 예측한 것 중 실제 긍정인 비율
- **재현율(Recall)**
    - 실제 긍정인 것 중 모델이 긍정이라고 정확하게 예측한 비율
- **F1-Score**
    - 정밀도와 재현율의 조화 평균
- **혼동 행렬(Confusion Matrix)**
    - 모델의 예측과 실제 값을 비교하여 오분류 유형을 보여주는 표
- **ROC Curve (Receiver Operating Characteristic Curve) & AUC (Area Under the Curve)**
    - 분류 모델의 임계값에 따른 성능 변화를 시각화하고, 모델의 전반적인 분류 성능을 나타내는 지표

#### 3.2 회귀(Regression) 모델
- 연속적인 값을 예측하는 모델
    - 예: 주택 가격 예측, 주식 가격 예측<br><br>
- **MAE (Mean Absolute Error)**
    - 실제 값과 예측 값 차이의 절댓값 평균
- **MSE (Mean Squared Error)**
    - 실제 값과 예측 값 차이의 제곱 평균
- **RMSE (Root Mean Squared Error)**
    - MSE에 루트를 씌운 값
    - 오차의 크기를 실제 값과 비슷한 단위로 해석할 수 있음
- **R-squared**
    - 모델이 분산을 얼마나 잘 설명하는지 나타내는 지표 (0~1 사이)

#### 3.3생성형(Generative) 모델
- 텍스트, 이미지, 음성 등 새로운 콘텐츠를 생성하는 모델<br><br>
- **BLEU (Bilingual Evaluation Understudy)**
    - 생성된 텍스트가 참조(정답) 텍스트와 얼마나 일치하는지 n-gram을 기반으로 평가
    - 텍스트 번역이나 요약에 주로 사용
- **ROUGE (Recall-Oriented Understudy for Gisting Evaluation)**
    - 주로 문서 요약 품질을 평가하는 지표
    - 생성된 요약과 기준 요약 간의 재현율을 측정함
- **Perplexity**
    - 언어 모델이 새로운 샘플을 얼마나 잘 예측하는지 측정하는 지표
    - 값이 낮을수록 모델 성능이 좋음
- **FID (Fréchet Inception Distance)**
    - 생성된 이미지의 품질을 평가하는 지표
- **CLIP Score**
    - 이미지와 텍스트의 일치도를 평가하는 지표
    - 텍스트-이미지 생성 모델에 활용

### 4. AI 모델 검증 기술

- 단순히 성능 지표를 넘어서, AI 모델이 실제 서비스 환경에서 얼마나 '제대로' 작동하는지 확인하기 위한 기술들

- **견고성(Robustness) 검증**
    - **최대 안전 반경 테스트(Maximum Safe Radius Test)**
        - 입력 데이터에 작은 변화를 주었을 때 모델의 예측이 변경되지 않는 최대 반경을 계산하여 모델의 견고성을 측정
    - **적대적 예제(Adversarial Examples) 테스트**
        - 모델을 의도적으로 오판하게 만드는 미묘하게 조작된 입력 데이터를 사용하여 모델의 취약점을 탐지

- **설명 가능성(Explainability) 검증 (XAI)**
    - AI 모델이 특정 결정을 내린 이유를 사람이 이해할 수 있는 형태로 설명하는 능력을 평가
    - 블랙박스 모델의 투명성을 높여 모델의 신뢰도 향상

- **공정성(Fairness) 검증**
    - AI 모델이 특정 집단(성별, 인종 등)에 대해 편향된 결과를 내지 않는지 확인
    - 사회적 불평등을 야기할 수 있는 AI의 윤리적 문제를 해결하는 데 중요

- **커버리지 검증**
    - **뉴런 커버리지(Neuron Coverage) 테스트**
        - 신경망의 내부 뉴런들이 테스트 실행 중에 얼마나 활성화되었는지 측정
        - 모델의 다양한 내부 상태가 충분히 테스트되었는지 확인
    - **결정 경계 커버리지(Decision Boundary Coverage)**
        - AI 모델의 의사 결정 경계(클래스를 나누는 기준)가 테스트를 통해 얼마나 잘 탐색되었는지 측정
    - **입력 공간 커버리지(Input Space Coverage)**
        - 모델이 처리해야 할 전체 입력 데이터 공간 중 얼마나 많은 부분이 테스트되었는지 확인

- **메타모픽 테스트(Metamorphic Testing)**
    - 테스트 오라클 문제(정확한 기대 출력 값을 알기 어려운 상황)를 해결하기 위한 기법
    - 입력과 출력 간의 "변형 관계(metamorphic relation)"를 정의하여 소프트웨어의 신뢰성을 검증
